#dbeta(k.star, shape1 = a, shape2 = b, log = TRUE) +
dgamma(R0.star, shape = R0/R0_var, scale = R0_var, log = TRUE)
if(is.na(exp(mh.num-mh.denom))){
print(paste0("mh.num: ", mh.num))
print(paste0("mh.denom: ", mh.denom))
print(paste0("k: ", k.star))
print(paste0("R0: ", R0.star))
print(paste0("p: ", p.star))
}
if(runif(1) < exp(mh.num-mh.denom)){
pars.fit$R0 = R0.star
pars.fit$k = k.star
update.pars = update.pars+1 ## count updated parameters
}
## save out parameters
pars.save[iter,1] = pars.fit$R0
pars.save[iter,2] = pars.fit$k*lim
## adapt
# if(iter%%n_adapt == 0){
#   ## move adapt counter up 1
#   adapt.t=adapt.t+1
#   ## new tuning parameters for beta
#   adapt.vals=get.sigma(s2.tune = s2.tune, Sigma.tune = S2, data = pars.save[(iter-n_adapt)+1:n_adapt,], accept = update.pars, t.adapt = adapt.t)
#   S2=adapt.vals$Sigma
#   s2=adapt.vals$s2
#   ## resetting acceptances to 0
#   update.pars=0
# }
} ## overcome
update.pars/n.mcmc
effectiveSize(pars.save)
# matplot(pars.save,type="l")
burnin = 1000
pars.save = as.data.frame(pars.save)
pars.save = pars.save[-(1:burnin),]
pars.save_thin = pars.save[seq(0,dim(pars.save)[1], 500),]
names(pars.save) <- names(pars.true)
as.data.frame(lapply(pars.save, mean))
pars.true
abs(as.data.frame(lapply(pars.save, mean)) - pars.true)
dim(tst)[1]
# parameter validation plots
plot(pars.save$R0, type="l")
abline(h = mean(pars.save$R0), col = "red", lwd = 3)
abline(h = pars.true$R0, col = "gold", lwd = 3)
abline(h = quantile(pars.save$R0, c(.025, .975)), col = "aquamarine", lty = "dashed", lwd = 2)
# Generate transmission tree
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
# Generate transmission tree
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
# Generate transmission tree
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
# Generate transmission tree
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
pars.true = data.frame(R0 = 2, k = 10)
model.pars <- data.frame(model_type = 0, R0 = pars.true$R0, R0_SS = 10, prob_SS = 0.05, k = pars.true$k,
data_type = 0, reps = 10, N_threshold = 5000,
data_path = "na"
)
# Generate transmission tree
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
# print(sum(tmp$to == -1))
tmp = tmp[!(tmp$to == -1),] ## remove terminal nodes with no offspring distribution due to simulation threshold
# Calculate out-degree: Count how many times each node appears in "from"
out_degree = tmp %>% count(from)
out_degree$n[out_degree$from == 1] = out_degree$n[out_degree$from == 1] - 1 ## reduce focal node magnitude by one, since it contains a self reference for visualization purposes
out_data = data.frame(node = 1:dim(tmp)[1], out_degree = 0)
out_data$out_degree[unique(tmp$from)] = out_degree$n
out_data$tree_ID <- i
tmp
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
# Calculate out-degree: Count how many times each node appears in "from"
out_degree = tmp %>% count(from)
out_degree
# print(sum(tmp$to == -1))
tmp = tmp[!(tmp$to == -1),] ## remove terminal nodes with no offspring distribution due to simulation threshold
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
# Calculate out-degree: Count how many times each node appears in "from"
out_degree = tmp %>% count(from)
sum(out_degree$n == 0)
pars.true = data.frame(R0 = 2, k = 10)
model.pars <- data.frame(model_type = 0, R0 = pars.true$R0, R0_SS = 10, prob_SS = 0.05, k = pars.true$k,
data_type = 0, reps = 10, N_threshold = 50,
data_path = "na"
)
library(dplyr)
library(coda)
N <- 1  # Number of spillover events
## generate outbreak data for each spillover
tst <- lapply(1:N, function(i) {
# Generate transmission tree
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
# print(sum(tmp$to == -1))
tmp = tmp[!(tmp$to == -1),] ## remove terminal nodes with no offspring distribution due to simulation threshold
# Calculate out-degree: Count how many times each node appears in "from"
out_degree = tmp %>% count(from)
out_degree$n[out_degree$from == 1] = out_degree$n[out_degree$from == 1] - 1 ## reduce focal node magnitude by one, since it contains a self reference for visualization purposes
out_data = data.frame(node = 1:dim(tmp)[1], out_degree = 0)
out_data$out_degree[unique(tmp$from)] = out_degree$n
out_data$tree_ID <- i
return(out_data)
}) %>% bind_rows()
# Generate transmission tree
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
View(tmp)
tmp %>% count(from)
# print(sum(tmp$to == -1))
tmp = tmp[!(tmp$to == -1),] ## remove terminal nodes with no offspring distribution due to simulation threshold
# Calculate out-degree: Count how many times each node appears in "from"
out_degree = tmp %>% count(from)
tmp %>% count(from)
out_degree$n[out_degree$from == 1] = out_degree$n[out_degree$from == 1] - 1 ## reduce focal node magnitude by one, since it contains a self reference for visualization purposes
out_degree
tmp
pars.true = data.frame(R0 = 2, k = 10)
model.pars <- data.frame(model_type = 0, R0 = pars.true$R0, R0_SS = 10, prob_SS = 0.05, k = pars.true$k,
data_type = 0, reps = 10, N_threshold = 50,
data_path = "na"
)
library(dplyr)
library(coda)
N <- 1  # Number of spillover events
## generate outbreak data for each spillover
tst <- lapply(1:N, function(i) {
# Generate transmission tree
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
# print(sum(tmp$to == -1))
tmp = tmp[!(tmp$to == -1),] ## remove terminal nodes with no offspring distribution due to simulation threshold
# Calculate out-degree: Count how many times each node appears in "from"
out_degree = tmp %>% count(from)
out_degree$n[out_degree$from == 1] = out_degree$n[out_degree$from == 1] - 1 ## reduce focal node magnitude by one, since it contains a self reference for visualization purposes
out_data = data.frame(node = 1:max(tmp$from), out_degree = 0)
out_data$out_degree[unique(tmp$from)] = out_degree$n
out_data$tree_ID <- i
return(out_data)
}) %>% bind_rows()
dim(tst)[1]
n.mcmc = 50000
n_adapt = 500
pars.fit = data.frame(R0 = 1, k = pars.true$k) ## initial parameter values
model.pars[names(pars.fit)] = pars.fit
pars.save = matrix(NA, ncol = dim(pars.fit)[2], nrow = n.mcmc)
update.pars = 0
y = tst$out_degree
y = rnbinom(n=50, mu = pars.true$R0, size = pars.true$k)
get.p = function(R0, k){(1 + (R0/k))^(-1)} ## converts true model parameters into NB prob parameter
## R0~gamma; k~lim*Beta
## prior hyperparameters
k_var = 0.01; lim = 1;
R0_var = 0.5;
for(iter in 1:n.mcmc){
# print out every 100 iterations to track progress
if(iter%%100 == 0){
cat(iter," ")
}
## initial parameters
k = as.numeric(pars.fit['k'])
R0 = as.numeric(pars.fit['R0'])
p = get.p(R0 = R0, k = k)
adapt.t = 0
## improvise
## propose MH value for R0, k
# k.star = rgamma(1, shape = k/k_var, scale = k_var) ## gamma proposal
v = (k*(1-k)/k_var)-1; a = k*v; b = (1-k)*v ## compute beta parameters using mean-variance parameterization
# k.star = rbeta(1, shape1 = a, shape2 = b) ## stretched beta proposal
k.star = k
v.star = (k.star*(1-k.star)/k_var)-1; a.star = (k.star)*v; b.star = (1-k.star)*v ## compute proposal beta parameters using mean-variance parameterization
R0.star = rgamma(1, shape = R0/R0_var, scale = R0_var)
p.star = get.p(R0 = R0.star, k = k.star) # convert sampled parameters into NB parameter p
## gamma proposal MH ratio terms
# mh.num = sum( dnbinom(y, size = k.star, prob = p.star, log = TRUE) )  +
#   dgamma(k, shape = k.star/k_var, scale = k_var, log = TRUE) + dgamma(R0, shape = R0.star/R0_var, scale = R0_var, log = TRUE)
#
# mh.denom = sum( dnbinom(y, size = k, prob = p, log = TRUE) ) +
#               dgamma(k.star, shape = k/k_var, scale = k_var, log = TRUE) + dgamma(R0.star, shape = R0/R0_var, scale = R0_var, log = TRUE)
#
## beta proposal on k MH ratio terms
# mh.num = sum( dnbinom(y, size = lim*k.star, prob = p.star, log = TRUE) )  +
#   #dbeta(k, shape1 = a.star, shape2 = b.star, log = TRUE) +
#   dgamma(R0, shape = R0.star/R0_var, scale = R0_var, log = TRUE)
#
# mh.denom = sum( dnbinom(y, size = lim*k, prob = p, log = TRUE) ) +
#   #dbeta(k.star, shape1 = a, shape2 = b, log = TRUE) +
#   dgamma(R0.star, shape = R0/R0_var, scale = R0_var, log = TRUE)
## beta proposal on k MH ratio terms
mh.num = sum( dnbinom(y, mu = R0.star, size = k.star, log = TRUE) )  +
#dbeta(k, shape1 = a.star, shape2 = b.star, log = TRUE) +
dgamma(R0, shape = R0.star/R0_var, scale = R0_var, log = TRUE)
mh.denom = sum( dnbinom(y, mu = R0, size = k, log = TRUE) ) +
#dbeta(k.star, shape1 = a, shape2 = b, log = TRUE) +
dgamma(R0.star, shape = R0/R0_var, scale = R0_var, log = TRUE)
if(is.na(exp(mh.num-mh.denom))){
print(paste0("mh.num: ", mh.num))
print(paste0("mh.denom: ", mh.denom))
print(paste0("k: ", k.star))
print(paste0("R0: ", R0.star))
print(paste0("p: ", p.star))
}
if(runif(1) < exp(mh.num-mh.denom)){
pars.fit$R0 = R0.star
pars.fit$k = k.star
update.pars = update.pars+1 ## count updated parameters
}
## save out parameters
pars.save[iter,1] = pars.fit$R0
pars.save[iter,2] = pars.fit$k*lim
## adapt
# if(iter%%n_adapt == 0){
#   ## move adapt counter up 1
#   adapt.t=adapt.t+1
#   ## new tuning parameters for beta
#   adapt.vals=get.sigma(s2.tune = s2.tune, Sigma.tune = S2, data = pars.save[(iter-n_adapt)+1:n_adapt,], accept = update.pars, t.adapt = adapt.t)
#   S2=adapt.vals$Sigma
#   s2=adapt.vals$s2
#   ## resetting acceptances to 0
#   update.pars=0
# }
} ## overcome
update.pars/n.mcmc
effectiveSize(pars.save)
# matplot(pars.save,type="l")
burnin = 1000
pars.save = as.data.frame(pars.save)
pars.save = pars.save[-(1:burnin),]
pars.save_thin = pars.save[seq(0,dim(pars.save)[1], 500),]
names(pars.save) <- names(pars.true)
as.data.frame(lapply(pars.save, mean))
pars.true
abs(as.data.frame(lapply(pars.save, mean)) - pars.true)
dim(tst)[1]
# parameter validation plots
plot(pars.save$R0, type="l")
abline(h = mean(pars.save$R0), col = "red", lwd = 3)
abline(h = pars.true$R0, col = "gold", lwd = 3)
abline(h = quantile(pars.save$R0, c(.025, .975)), col = "aquamarine", lty = "dashed", lwd = 2)
pars.true = data.frame(R0 = 2, k = 10)
model.pars <- data.frame(model_type = 0, R0 = pars.true$R0, R0_SS = 10, prob_SS = 0.05, k = pars.true$k,
data_type = 0, reps = 10, N_threshold = 50,
data_path = "na"
)
library(dplyr)
library(coda)
N <- 1  # Number of spillover events
## generate outbreak data for each spillover
tst <- lapply(1:N, function(i) {
# Generate transmission tree
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
# print(sum(tmp$to == -1))
tmp = tmp[!(tmp$to == -1),] ## remove terminal nodes with no offspring distribution due to simulation threshold
# Calculate out-degree: Count how many times each node appears in "from"
out_degree = tmp %>% count(from)
out_degree$n[out_degree$from == 1] = out_degree$n[out_degree$from == 1] - 1 ## reduce focal node magnitude by one, since it contains a self reference for visualization purposes
out_data = data.frame(node = 1:max(tmp$from), out_degree = 0)
out_data$out_degree[unique(tmp$from)] = out_degree$n
out_data$tree_ID <- i
return(out_data)
}) %>% bind_rows()
dim(tst)[1]
n.mcmc = 50000
n_adapt = 500
pars.fit = data.frame(R0 = 1, k = pars.true$k) ## initial parameter values
model.pars[names(pars.fit)] = pars.fit
pars.save = matrix(NA, ncol = dim(pars.fit)[2], nrow = n.mcmc)
update.pars = 0
y = tst$out_degree
# y = rnbinom(n=50, mu = pars.true$R0, size = pars.true$k)
get.p = function(R0, k){(1 + (R0/k))^(-1)} ## converts true model parameters into NB prob parameter
## R0~gamma; k~lim*Beta
## prior hyperparameters
k_var = 0.01; lim = 1;
R0_var = 0.5;
for(iter in 1:n.mcmc){
# print out every 100 iterations to track progress
if(iter%%100 == 0){
cat(iter," ")
}
## initial parameters
k = as.numeric(pars.fit['k'])
R0 = as.numeric(pars.fit['R0'])
p = get.p(R0 = R0, k = k)
adapt.t = 0
## improvise
## propose MH value for R0, k
# k.star = rgamma(1, shape = k/k_var, scale = k_var) ## gamma proposal
v = (k*(1-k)/k_var)-1; a = k*v; b = (1-k)*v ## compute beta parameters using mean-variance parameterization
# k.star = rbeta(1, shape1 = a, shape2 = b) ## stretched beta proposal
k.star = k
v.star = (k.star*(1-k.star)/k_var)-1; a.star = (k.star)*v; b.star = (1-k.star)*v ## compute proposal beta parameters using mean-variance parameterization
R0.star = rgamma(1, shape = R0/R0_var, scale = R0_var)
p.star = get.p(R0 = R0.star, k = k.star) # convert sampled parameters into NB parameter p
## gamma proposal MH ratio terms
# mh.num = sum( dnbinom(y, size = k.star, prob = p.star, log = TRUE) )  +
#   dgamma(k, shape = k.star/k_var, scale = k_var, log = TRUE) + dgamma(R0, shape = R0.star/R0_var, scale = R0_var, log = TRUE)
#
# mh.denom = sum( dnbinom(y, size = k, prob = p, log = TRUE) ) +
#               dgamma(k.star, shape = k/k_var, scale = k_var, log = TRUE) + dgamma(R0.star, shape = R0/R0_var, scale = R0_var, log = TRUE)
#
## beta proposal on k MH ratio terms
# mh.num = sum( dnbinom(y, size = lim*k.star, prob = p.star, log = TRUE) )  +
#   #dbeta(k, shape1 = a.star, shape2 = b.star, log = TRUE) +
#   dgamma(R0, shape = R0.star/R0_var, scale = R0_var, log = TRUE)
#
# mh.denom = sum( dnbinom(y, size = lim*k, prob = p, log = TRUE) ) +
#   #dbeta(k.star, shape1 = a, shape2 = b, log = TRUE) +
#   dgamma(R0.star, shape = R0/R0_var, scale = R0_var, log = TRUE)
## beta proposal on k MH ratio terms
mh.num = sum( dnbinom(y, mu = R0.star, size = k.star, log = TRUE) )  +
#dbeta(k, shape1 = a.star, shape2 = b.star, log = TRUE) +
dgamma(R0, shape = R0.star/R0_var, scale = R0_var, log = TRUE)
mh.denom = sum( dnbinom(y, mu = R0, size = k, log = TRUE) ) +
#dbeta(k.star, shape1 = a, shape2 = b, log = TRUE) +
dgamma(R0.star, shape = R0/R0_var, scale = R0_var, log = TRUE)
if(is.na(exp(mh.num-mh.denom))){
print(paste0("mh.num: ", mh.num))
print(paste0("mh.denom: ", mh.denom))
print(paste0("k: ", k.star))
print(paste0("R0: ", R0.star))
print(paste0("p: ", p.star))
}
if(runif(1) < exp(mh.num-mh.denom)){
pars.fit$R0 = R0.star
pars.fit$k = k.star
update.pars = update.pars+1 ## count updated parameters
}
## save out parameters
pars.save[iter,1] = pars.fit$R0
pars.save[iter,2] = pars.fit$k*lim
## adapt
# if(iter%%n_adapt == 0){
#   ## move adapt counter up 1
#   adapt.t=adapt.t+1
#   ## new tuning parameters for beta
#   adapt.vals=get.sigma(s2.tune = s2.tune, Sigma.tune = S2, data = pars.save[(iter-n_adapt)+1:n_adapt,], accept = update.pars, t.adapt = adapt.t)
#   S2=adapt.vals$Sigma
#   s2=adapt.vals$s2
#   ## resetting acceptances to 0
#   update.pars=0
# }
} ## overcome
update.pars/n.mcmc
effectiveSize(pars.save)
# matplot(pars.save,type="l")
burnin = 1000
pars.save = as.data.frame(pars.save)
pars.save = pars.save[-(1:burnin),]
pars.save_thin = pars.save[seq(0,dim(pars.save)[1], 500),]
names(pars.save) <- names(pars.true)
as.data.frame(lapply(pars.save, mean))
pars.true
abs(as.data.frame(lapply(pars.save, mean)) - pars.true)
dim(tst)[1]
############################
############################
# parameter validation plots
plot(pars.save$R0, type="l")
abline(h = mean(pars.save$R0), col = "red", lwd = 3)
abline(h = pars.true$R0, col = "gold", lwd = 3)
abline(h = quantile(pars.save$R0, c(.025, .975)), col = "aquamarine", lty = "dashed", lwd = 2)
length(y)
pars.true = data.frame(R0 = 1.1, k = 0.4)
model.pars <- data.frame(model_type = 0, R0 = pars.true$R0, R0_SS = 10, prob_SS = 0.05, k = pars.true$k,
data_type = 0, reps = 10, N_threshold = 50,
data_path = "na"
)
library(dplyr)
library(coda)
N <- 5  # Number of spillover events
## generate outbreak data for each spillover
tst <- lapply(1:N, function(i) {
# Generate transmission tree
tmp <- transmissionTree_sim(n_reps = 1, parameters = model.pars)
# print(sum(tmp$to == -1))
tmp = tmp[!(tmp$to == -1),] ## remove terminal nodes with no offspring distribution due to simulation threshold
# Calculate out-degree: Count how many times each node appears in "from"
out_degree = tmp %>% count(from)
out_degree$n[out_degree$from == 1] = out_degree$n[out_degree$from == 1] - 1 ## reduce focal node magnitude by one, since it contains a self reference for visualization purposes
out_data = data.frame(node = 1:max(tmp$from), out_degree = 0)
out_data$out_degree[unique(tmp$from)] = out_degree$n
out_data$tree_ID <- i
return(out_data)
}) %>% bind_rows()
dim(tst)[1]
n.mcmc = 50000
n_adapt = 500
pars.fit = data.frame(R0 = 1, k = pars.true$k) ## initial parameter values
model.pars[names(pars.fit)] = pars.fit
pars.save = matrix(NA, ncol = dim(pars.fit)[2], nrow = n.mcmc)
update.pars = 0
y = tst$out_degree
get.p = function(R0, k){(1 + (R0/k))^(-1)} ## converts true model parameters into NB prob parameter
## R0~gamma; k~lim*Beta
## prior hyperparameters
k_var = 0.01; lim = 1;
R0_var = 0.5;
for(iter in 1:n.mcmc){
# print out every 100 iterations to track progress
if(iter%%100 == 0){
cat(iter," ")
}
## initial parameters
k = as.numeric(pars.fit['k'])
R0 = as.numeric(pars.fit['R0'])
p = get.p(R0 = R0, k = k)
adapt.t = 0
## improvise
## propose MH value for R0, k
# k.star = rgamma(1, shape = k/k_var, scale = k_var) ## gamma proposal
v = (k*(1-k)/k_var)-1; a = k*v; b = (1-k)*v ## compute beta parameters using mean-variance parameterization
# k.star = rbeta(1, shape1 = a, shape2 = b) ## stretched beta proposal
k.star = k
v.star = (k.star*(1-k.star)/k_var)-1; a.star = (k.star)*v; b.star = (1-k.star)*v ## compute proposal beta parameters using mean-variance parameterization
R0.star = rgamma(1, shape = R0/R0_var, scale = R0_var)
p.star = get.p(R0 = R0.star, k = k.star) # convert sampled parameters into NB parameter p
## gamma proposal MH ratio terms
# mh.num = sum( dnbinom(y, size = k.star, prob = p.star, log = TRUE) )  +
#   dgamma(k, shape = k.star/k_var, scale = k_var, log = TRUE) + dgamma(R0, shape = R0.star/R0_var, scale = R0_var, log = TRUE)
#
# mh.denom = sum( dnbinom(y, size = k, prob = p, log = TRUE) ) +
#               dgamma(k.star, shape = k/k_var, scale = k_var, log = TRUE) + dgamma(R0.star, shape = R0/R0_var, scale = R0_var, log = TRUE)
#
## beta proposal on k MH ratio terms
# mh.num = sum( dnbinom(y, size = lim*k.star, prob = p.star, log = TRUE) )  +
#   #dbeta(k, shape1 = a.star, shape2 = b.star, log = TRUE) +
#   dgamma(R0, shape = R0.star/R0_var, scale = R0_var, log = TRUE)
#
# mh.denom = sum( dnbinom(y, size = lim*k, prob = p, log = TRUE) ) +
#   #dbeta(k.star, shape1 = a, shape2 = b, log = TRUE) +
#   dgamma(R0.star, shape = R0/R0_var, scale = R0_var, log = TRUE)
## beta proposal on k MH ratio terms
mh.num = sum( dnbinom(y, mu = R0.star, size = k.star, log = TRUE) )  +
#dbeta(k, shape1 = a.star, shape2 = b.star, log = TRUE) +
dgamma(R0, shape = R0.star/R0_var, scale = R0_var, log = TRUE)
mh.denom = sum( dnbinom(y, mu = R0, size = k, log = TRUE) ) +
#dbeta(k.star, shape1 = a, shape2 = b, log = TRUE) +
dgamma(R0.star, shape = R0/R0_var, scale = R0_var, log = TRUE)
if(is.na(exp(mh.num-mh.denom))){
print(paste0("mh.num: ", mh.num))
print(paste0("mh.denom: ", mh.denom))
print(paste0("k: ", k.star))
print(paste0("R0: ", R0.star))
print(paste0("p: ", p.star))
}
if(runif(1) < exp(mh.num-mh.denom)){
pars.fit$R0 = R0.star
pars.fit$k = k.star
update.pars = update.pars+1 ## count updated parameters
}
## save out parameters
pars.save[iter,1] = pars.fit$R0
pars.save[iter,2] = pars.fit$k*lim
## adapt
# if(iter%%n_adapt == 0){
#   ## move adapt counter up 1
#   adapt.t=adapt.t+1
#   ## new tuning parameters for beta
#   adapt.vals=get.sigma(s2.tune = s2.tune, Sigma.tune = S2, data = pars.save[(iter-n_adapt)+1:n_adapt,], accept = update.pars, t.adapt = adapt.t)
#   S2=adapt.vals$Sigma
#   s2=adapt.vals$s2
#   ## resetting acceptances to 0
#   update.pars=0
# }
} ## overcome
update.pars/n.mcmc
effectiveSize(pars.save)
# matplot(pars.save,type="l")
burnin = 1000
pars.save = as.data.frame(pars.save)
pars.save = pars.save[-(1:burnin),]
pars.save_thin = pars.save[seq(0,dim(pars.save)[1], 500),]
names(pars.save) <- names(pars.true)
as.data.frame(lapply(pars.save, mean))
pars.true
abs(as.data.frame(lapply(pars.save, mean)) - pars.true)
dim(tst)[1]
# parameter validation plots
plot(pars.save$R0, type="l")
abline(h = mean(pars.save$R0), col = "red", lwd = 3)
abline(h = pars.true$R0, col = "gold", lwd = 3)
abline(h = quantile(pars.save$R0, c(.025, .975)), col = "aquamarine", lty = "dashed", lwd = 2)
sample(1:6, 8)
sample(8, 1:6)
sample(size = 8, x = 1:6, replace = T)
